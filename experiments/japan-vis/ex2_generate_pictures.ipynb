{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuga_takata/dev/vdslab-project/hyperparameter-in-graph-drawing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import json\n",
    "import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "# Third Party Library\n",
    "import pandas as pd\n",
    "from ex_utils.config.paths import get_dataset_path\n",
    "from ex_utils.config.quality_metrics import qm_names\n",
    "from ex_utils.share import (\n",
    "    ex_path,\n",
    "    generate_seed_median_df,\n",
    "    generate_sscalers,\n",
    ")\n",
    "from ex_utils.utils.graph import (\n",
    "    load_nx_graph,\n",
    "    nx_graph_preprocessing,\n",
    ")\n",
    "\n",
    "# Standard Library\n",
    "import argparse\n",
    "from time import perf_counter\n",
    "\n",
    "# Third Party Library\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from egraph import Drawing, all_sources_bfs\n",
    "from ex_utils.config.dataset import dataset_names\n",
    "from ex_utils.config.paths import get_dataset_path\n",
    "from ex_utils.config.quality_metrics import qm_names\n",
    "from ex_utils.share import draw, ex_path, generate_base_df_data, rate2pivots\n",
    "from ex_utils.utils.graph import (\n",
    "    egraph_graph,\n",
    "    load_nx_graph,\n",
    "    nx_graph_preprocessing,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "export_data = {}\n",
    "\n",
    "EDGE_WEIGHT = 30\n",
    "d_names = sorted(\n",
    "    [\n",
    "        \"1138_bus\",\n",
    "        \"USpowerGrid\",\n",
    "        \"dwt_1005\",\n",
    "        \"poli\",\n",
    "        \"qh882\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "seeds = list(range(15))\n",
    "n_split = 10\n",
    "multi_n_trials = 300\n",
    "single_n_trials = 300\n",
    "\n",
    "pref_array = [0.5, 0.5, 0.5, 5.0, 2.0, 0.5, 4.0, 0.5, 4.0, 0.5]\n",
    "pref = dict(zip(qm_names, pref_array))\n",
    "drawing_seeds = list(range(3))\n",
    "\n",
    "params = dict(\n",
    "    zip(\n",
    "        d_names,\n",
    "        [\n",
    "            {\"empirical\": {\"pivots\": 50, \"iterations\": 100, \"eps\": 0.1}}\n",
    "            for _ in range(len(d_names))\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "def gen_pic(params, eg_graph, nx_graph, eg_indices, seed, path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig, axes = plt.subplots(\n",
    "        figsize=(8, 8),\n",
    "        dpi=300,\n",
    "        facecolor=\"white\",\n",
    "        ncols=1,\n",
    "        nrows=1,\n",
    "        squeeze=False,\n",
    "    )\n",
    "    ax = axes[0][0]\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "    eg_drawing = Drawing.initial_placement(eg_graph)\n",
    "    pos = draw(\n",
    "        pivots=params[\"pivots\"],\n",
    "        iterations=params[\"iterations\"],\n",
    "        eps=params[\"eps\"],\n",
    "        eg_graph=eg_graph,\n",
    "        eg_indices=eg_indices,\n",
    "        eg_drawing=eg_drawing,\n",
    "        edge_weight=EDGE_WEIGHT,\n",
    "        seed=seed,\n",
    "    )\n",
    "    nx.draw(\n",
    "        nx_graph,\n",
    "        pos=pos,\n",
    "        node_size=3,\n",
    "        # node_color=\"#AB47BC\",\n",
    "        width=1,\n",
    "        edge_color=\"#CFD8DC\",\n",
    "        ax=ax,\n",
    "        margins=0,\n",
    "    )\n",
    "\n",
    "    # ax.set_axis_on()\n",
    "    ax.tick_params(left=True, bottom=True, labelleft=True, labelbottom=True)\n",
    "    plt.tight_layout(pad=-1)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "for d_name in d_names:\n",
    "    export_data[d_name] = []\n",
    "    df_paths = [\n",
    "        ex_path.joinpath(\n",
    "            f\"data/grid/{d_name}/n_split={n_split}/seed={seed}.pkl\"\n",
    "        )\n",
    "        for seed in seeds\n",
    "    ]\n",
    "    df = pd.concat([pd.read_pickle(path) for path in df_paths])\n",
    "    df = generate_seed_median_df(df)\n",
    "    scalers = generate_sscalers(df)\n",
    "\n",
    "    dataset_path = get_dataset_path(d_name)\n",
    "    nx_graph = nx_graph_preprocessing(\n",
    "        load_nx_graph(dataset_path=dataset_path), EDGE_WEIGHT\n",
    "    )\n",
    "    p_max = max(1, int(len(nx_graph.nodes) * 0.25))\n",
    "    eg_graph, eg_indices = egraph_graph(nx_graph=nx_graph)\n",
    "    eg_distance_matrix = all_sources_bfs(eg_graph, EDGE_WEIGHT)\n",
    "\n",
    "    multi_obj_study_name = f\"multi-obj-{multi_n_trials}\"\n",
    "    multi_db_uri = f'sqlite:///{ex_path.joinpath(f\"data/optimization/{d_name}-multi-obj.db\")}'\n",
    "    multi_obj_study = optuna.load_study(\n",
    "        storage=multi_db_uri, study_name=multi_obj_study_name\n",
    "    )\n",
    "    pareto_front = list(multi_obj_study.best_trials)\n",
    "\n",
    "    # multi\n",
    "    multi = -float(\"inf\")\n",
    "    for pareto_optimal in pareto_front:\n",
    "        pareto_optimal_quality_metrics = pareto_optimal.user_attrs[\n",
    "            \"median_quality_metrics\"\n",
    "        ]\n",
    "        pareto_optimal_scaled_quality_metrics = dict(\n",
    "            [\n",
    "                (\n",
    "                    qm_name,\n",
    "                    scalers[qm_name].transform(\n",
    "                        [[pareto_optimal_quality_metrics[qm_name]]]\n",
    "                    )[0][0],\n",
    "                )\n",
    "                for qm_name in qm_names\n",
    "            ]\n",
    "        )\n",
    "        pareto_optimal_scaled_quality_metrics_sum = sum(\n",
    "            [\n",
    "                pareto_optimal_scaled_quality_metrics[qm_name] * pref[qm_name]\n",
    "                for qm_name in qm_names\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if multi < pareto_optimal_scaled_quality_metrics_sum:\n",
    "            multi = pareto_optimal_scaled_quality_metrics_sum\n",
    "            params[d_name][\"multi\"] = pareto_optimal.params\n",
    "\n",
    "    # single\n",
    "    single_obj_study_name = f'single-obj_{\",\".join(map(str, pref_array))}'\n",
    "    single_db_uri = f'sqlite:///{ex_path.joinpath(f\"data/optimization/{d_name}-user-experiment.db\")}'\n",
    "    sinigle_obj_study = optuna.load_study(\n",
    "        storage=single_db_uri, study_name=single_obj_study_name\n",
    "    )\n",
    "\n",
    "    params[d_name][\"single\"] = sinigle_obj_study.best_trial.params\n",
    "\n",
    "    for d_seed in drawing_seeds:\n",
    "        path = f\"data/exex/{d_name.replace('_', '-')}/empirical-{d_seed}.png\"\n",
    "        gen_pic(\n",
    "            params[d_name][\"empirical\"],\n",
    "            eg_graph,\n",
    "            nx_graph,\n",
    "            eg_indices,\n",
    "            d_seed,\n",
    "            ex_path.joinpath(path),\n",
    "        )\n",
    "\n",
    "        path = f\"data/exex/{d_name.replace('_', '-')}/multi-{d_seed}.png\"\n",
    "        gen_pic(\n",
    "            params[d_name][\"multi\"],\n",
    "            eg_graph,\n",
    "            nx_graph,\n",
    "            eg_indices,\n",
    "            d_seed,\n",
    "            ex_path.joinpath(path),\n",
    "        )\n",
    "\n",
    "        path = f\"data/exex/{d_name.replace('_', '-')}/single-{d_seed}.png\"\n",
    "        gen_pic(\n",
    "            params[d_name][\"single\"],\n",
    "            eg_graph,\n",
    "            nx_graph,\n",
    "            eg_indices,\n",
    "            d_seed,\n",
    "            ex_path.joinpath(path),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "with open(ex_path.joinpath(\"data/exex/params.json\"), mode=\"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def vertical_concat(img_a, img_b):\n",
    "    return vertical_concat_with_labels(img_a, \"A\", img_b, \"B\")\n",
    "\n",
    "\n",
    "def vertical_concat_with_labels(img_a, label_a, img_b, label_b):\n",
    "    dst = Image.new(\"RGB\", (img_a.width, img_a.height + img_b.height))\n",
    "    dst.paste(img_a, (0, 0))\n",
    "    dst.paste(img_b, (0, img_a.height))\n",
    "    draw = ImageDraw.Draw(dst)\n",
    "    x = img_a.width // 20\n",
    "    y = img_a.height // 20\n",
    "    font = ImageFont.truetype(font=\"Arial.ttf\", size=x)\n",
    "    draw.text((x, y), label_a, \"black\", font=font)\n",
    "    draw.text((x, y + img_a.height), label_b, \"black\", font=font)\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def horizontal_concat(img_a, img_b):\n",
    "    return horizontal_concat_with_labels(img_a, \"A\", img_b, \"B\")\n",
    "\n",
    "\n",
    "def horizontal_concat_with_labels(img_a, label_a, img_b, label_b):\n",
    "    dst = Image.new(\"RGB\", (img_a.width + img_b.width, img_a.height))\n",
    "    dst.paste(img_a, (0, 0))\n",
    "    dst.paste(img_b, (img_a.width, 0))\n",
    "    draw = ImageDraw.Draw(dst)\n",
    "    x = img_a.width // 20\n",
    "    y = img_a.height // 20\n",
    "    font = ImageFont.truetype(font=\"Arial.ttf\", size=x)\n",
    "    draw.text((x, y), label_a, \"black\", font=font)\n",
    "    draw.text((x + img_a.width, y), label_b, \"black\", font=font)\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "def save_img(img_a, label_a, img_b, label_b, d_name, uuid):\n",
    "    dpi = 300\n",
    "    vertical_concat(img_a, img_b).save(\n",
    "        ex_path.joinpath(\n",
    "            f\"data/exex/vertical_pictures/{d_name.replace('_','-')}/{uuid}.png\"\n",
    "        ),\n",
    "        dpi=(dpi, dpi),\n",
    "        quality=100,\n",
    "    )\n",
    "    vertical_concat_with_labels(\n",
    "        img_a,\n",
    "        label_a,\n",
    "        img_b,\n",
    "        label_b,\n",
    "    ).save(\n",
    "        ex_path.joinpath(\n",
    "            f\"data/exex/vertical_pictures_with_labels/{d_name.replace('_','-')}/{uuid}.png\"\n",
    "        ),\n",
    "        dpi=(dpi, dpi),\n",
    "        quality=100,\n",
    "    )\n",
    "\n",
    "    horizontal_concat(img_a, img_b).save(\n",
    "        ex_path.joinpath(\n",
    "            f\"data/exex/horizontal_pictures/{d_name.replace('_','-')}/{uuid}.png\"\n",
    "        ),\n",
    "        dpi=(dpi, dpi),\n",
    "        quality=100,\n",
    "    )\n",
    "    horizontal_concat_with_labels(\n",
    "        img_a,\n",
    "        label_a,\n",
    "        img_b,\n",
    "        label_b,\n",
    "    ).save(\n",
    "        ex_path.joinpath(\n",
    "            f\"data/exex/horizontal_pictures_with_labels/{d_name.replace('_','-')}/{uuid}.png\"\n",
    "        ),\n",
    "        dpi=(dpi, dpi),\n",
    "        quality=100,\n",
    "    )\n",
    "\n",
    "\n",
    "for d_name in d_names:\n",
    "    ex_path.joinpath(\n",
    "        f\"data/exex/vertical_pictures/{d_name.replace('_','-')}\"\n",
    "    ).mkdir(parents=True, exist_ok=True)\n",
    "    ex_path.joinpath(\n",
    "        f\"data/exex/horizontal_pictures/{d_name.replace('_','-')}\"\n",
    "    ).mkdir(parents=True, exist_ok=True)\n",
    "    ex_path.joinpath(\n",
    "        f\"data/exex/vertical_pictures_with_labels/{d_name.replace('_','-')}\"\n",
    "    ).mkdir(parents=True, exist_ok=True)\n",
    "    ex_path.joinpath(\n",
    "        f\"data/exex/horizontal_pictures_with_labels/{d_name.replace('_','-')}\"\n",
    "    ).mkdir(parents=True, exist_ok=True)\n",
    "export_data = {}\n",
    "types = [\"empirical\", \"multi\", \"single\"]\n",
    "for d_name in d_names:\n",
    "    for d_seed in drawing_seeds:\n",
    "        empirical = Image.open(\n",
    "            ex_path.joinpath(\n",
    "                f\"data/exex/{d_name.replace('_','-')}/empirical-{d_seed}.png\"\n",
    "            )\n",
    "        )\n",
    "        multi = Image.open(\n",
    "            ex_path.joinpath(\n",
    "                f\"data/exex/{d_name.replace('_','-')}/multi-{d_seed}.png\"\n",
    "            )\n",
    "        )\n",
    "        single = Image.open(\n",
    "            ex_path.joinpath(\n",
    "                f\"data/exex/{d_name.replace('_','-')}/single-{d_seed}.png\"\n",
    "            )\n",
    "        )\n",
    "        empirical_multi = [\n",
    "            {\"img\": empirical, \"type\": \"empirical\"},\n",
    "            {\"img\": multi, \"type\": \"multi\"},\n",
    "        ]\n",
    "        empirical_single = [\n",
    "            {\"img\": empirical, \"type\": \"empirical\"},\n",
    "            {\"img\": single, \"type\": \"single\"},\n",
    "        ]\n",
    "        multi_single = [\n",
    "            {\"img\": multi, \"type\": \"multi\"},\n",
    "            {\"img\": single, \"type\": \"single\"},\n",
    "        ]\n",
    "\n",
    "        shuffle(empirical_multi)\n",
    "        shuffle(empirical_single)\n",
    "        shuffle(multi_single)\n",
    "\n",
    "        uuid = str(uuid4())\n",
    "        export_data[uuid] = {\n",
    "            \"id\": uuid,\n",
    "            \"A\": empirical_multi[0][\"type\"],\n",
    "            \"B\": empirical_multi[1][\"type\"],\n",
    "            \"seed\": d_seed,\n",
    "            \"dataset\": d_name.replace(\"_\", \"-\"),\n",
    "        }\n",
    "        save_img(\n",
    "            empirical_multi[0][\"img\"],\n",
    "            empirical_multi[0][\"type\"],\n",
    "            empirical_multi[1][\"img\"],\n",
    "            empirical_multi[1][\"type\"],\n",
    "            d_name,\n",
    "            uuid,\n",
    "        )\n",
    "\n",
    "        uuid = str(uuid4())\n",
    "        export_data[uuid] = {\n",
    "            \"id\": uuid,\n",
    "            \"A\": empirical_single[0][\"type\"],\n",
    "            \"B\": empirical_single[1][\"type\"],\n",
    "            \"seed\": d_seed,\n",
    "            \"dataset\": d_name.replace(\"_\", \"-\"),\n",
    "        }\n",
    "        save_img(\n",
    "            empirical_single[0][\"img\"],\n",
    "            empirical_single[0][\"type\"],\n",
    "            empirical_single[1][\"img\"],\n",
    "            empirical_single[1][\"type\"],\n",
    "            d_name,\n",
    "            uuid,\n",
    "        )\n",
    "\n",
    "        uuid = str(uuid4())\n",
    "        export_data[uuid] = {\n",
    "            \"id\": uuid,\n",
    "            \"A\": multi_single[0][\"type\"],\n",
    "            \"B\": multi_single[1][\"type\"],\n",
    "            \"seed\": d_seed,\n",
    "            \"dataset\": d_name.replace(\"_\", \"-\"),\n",
    "        }\n",
    "        save_img(\n",
    "            multi_single[0][\"img\"],\n",
    "            multi_single[0][\"type\"],\n",
    "            multi_single[1][\"img\"],\n",
    "            multi_single[1][\"type\"],\n",
    "            d_name,\n",
    "            uuid,\n",
    "        )\n",
    "\n",
    "with open(ex_path.joinpath(\"data/exex/pictures.json\"), mode=\"w\") as f:\n",
    "    json.dump(export_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
