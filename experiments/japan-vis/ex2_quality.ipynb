{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuga_takata/dev/vdslab-project/hyperparameter-in-graph-drawing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import json\n",
    "import pprint\n",
    "from uuid import uuid4\n",
    "\n",
    "# Third Party Library\n",
    "import pandas as pd\n",
    "from ex_utils.config.paths import get_dataset_path\n",
    "from ex_utils.config.quality_metrics import qm_names\n",
    "from ex_utils.share import (\n",
    "    ex_path,\n",
    "    generate_seed_median_df,\n",
    "    generate_sscalers,\n",
    ")\n",
    "from ex_utils.utils.graph import (\n",
    "    load_nx_graph,\n",
    "    nx_graph_preprocessing,\n",
    ")\n",
    "\n",
    "# Standard Library\n",
    "import argparse\n",
    "from time import perf_counter\n",
    "\n",
    "# Third Party Library\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from egraph import Drawing, all_sources_bfs\n",
    "from ex_utils.config.dataset import dataset_names\n",
    "from ex_utils.config.paths import get_dataset_path\n",
    "from ex_utils.config.quality_metrics import qm_names\n",
    "from ex_utils.share import (\n",
    "    draw,\n",
    "    ex_path,\n",
    "    generate_base_df_data,\n",
    "    rate2pivots,\n",
    "    draw_and_measure,\n",
    ")\n",
    "from ex_utils.utils.graph import (\n",
    "    egraph_graph,\n",
    "    load_nx_graph,\n",
    "    nx_graph_preprocessing,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "export_data = {}\n",
    "\n",
    "EDGE_WEIGHT = 30\n",
    "d_names = sorted(\n",
    "    [\n",
    "        \"1138_bus\",\n",
    "        \"USpowerGrid\",\n",
    "        \"dwt_1005\",\n",
    "        \"poli\",\n",
    "        \"qh882\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "seeds = list(range(15))\n",
    "n_split = 10\n",
    "multi_n_trials = 300\n",
    "single_n_trials = 300\n",
    "\n",
    "pref_array = [0.5, 0.5, 0.5, 5.0, 2.0, 0.5, 4.0, 0.5, 4.0, 0.5]\n",
    "pref = dict(zip(qm_names, pref_array))\n",
    "drawing_seeds = list(range(3))\n",
    "\n",
    "params = dict(\n",
    "    zip(\n",
    "        d_names,\n",
    "        [\n",
    "            {\"empirical\": {\"pivots\": 50, \"iterations\": 100, \"eps\": 0.1}}\n",
    "            for _ in range(len(d_names))\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "for d_name in d_names:\n",
    "    export_data[d_name] = []\n",
    "    df_paths = [\n",
    "        ex_path.joinpath(\n",
    "            f\"data/grid/{d_name}/n_split={n_split}/seed={seed}.pkl\"\n",
    "        )\n",
    "        for seed in seeds\n",
    "    ]\n",
    "    df = pd.concat([pd.read_pickle(path) for path in df_paths])\n",
    "    df = generate_seed_median_df(df)\n",
    "    scalers = generate_sscalers(df)\n",
    "\n",
    "    dataset_path = get_dataset_path(d_name)\n",
    "    nx_graph = nx_graph_preprocessing(\n",
    "        load_nx_graph(dataset_path=dataset_path), EDGE_WEIGHT\n",
    "    )\n",
    "    p_max = max(1, int(len(nx_graph.nodes) * 0.25))\n",
    "    eg_graph, eg_indices = egraph_graph(nx_graph=nx_graph)\n",
    "    eg_distance_matrix = all_sources_bfs(eg_graph, EDGE_WEIGHT)\n",
    "\n",
    "    multi_obj_study_name = f\"multi-obj-{multi_n_trials}\"\n",
    "    multi_db_uri = f'sqlite:///{ex_path.joinpath(f\"data/optimization/{d_name}-multi-obj.db\")}'\n",
    "    multi_obj_study = optuna.load_study(\n",
    "        storage=multi_db_uri, study_name=multi_obj_study_name\n",
    "    )\n",
    "    pareto_front = list(multi_obj_study.best_trials)\n",
    "\n",
    "    # multi\n",
    "    multi = -float(\"inf\")\n",
    "    for pareto_optimal in pareto_front:\n",
    "        pareto_optimal_quality_metrics = pareto_optimal.user_attrs[\n",
    "            \"median_quality_metrics\"\n",
    "        ]\n",
    "        pareto_optimal_scaled_quality_metrics = dict(\n",
    "            [\n",
    "                (\n",
    "                    qm_name,\n",
    "                    scalers[qm_name].transform(\n",
    "                        [[pareto_optimal_quality_metrics[qm_name]]]\n",
    "                    )[0][0],\n",
    "                )\n",
    "                for qm_name in qm_names\n",
    "            ]\n",
    "        )\n",
    "        pareto_optimal_scaled_quality_metrics_sum = sum(\n",
    "            [\n",
    "                pareto_optimal_scaled_quality_metrics[qm_name] * pref[qm_name]\n",
    "                for qm_name in qm_names\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if multi < pareto_optimal_scaled_quality_metrics_sum:\n",
    "            multi = pareto_optimal_scaled_quality_metrics_sum\n",
    "            params[d_name][\"multi\"] = pareto_optimal.params\n",
    "\n",
    "    # single\n",
    "    single_obj_study_name = f'single-obj_{\",\".join(map(str, pref_array))}'\n",
    "    single_db_uri = f'sqlite:///{ex_path.joinpath(f\"data/optimization/{d_name}-user-experiment.db\")}'\n",
    "    sinigle_obj_study = optuna.load_study(\n",
    "        storage=single_db_uri, study_name=single_obj_study_name\n",
    "    )\n",
    "\n",
    "    params[d_name][\"single\"] = sinigle_obj_study.best_trial.params\n",
    "    sigle = sinigle_obj_study.best_trial.value\n",
    "\n",
    "    empirical = dict(zip(qm_names, [0 for _ in len(qm_names)]))\n",
    "    multi = dict(zip(qm_names, [0 for _ in len(qm_names)]))\n",
    "    single = dict(zip(qm_names, [0 for _ in len(qm_names)]))\n",
    "\n",
    "    # for d_seed in drawing_seeds:\n",
    "    #     eg_drawing = Drawing.initial_placement(eg_graph)\n",
    "    #     pos, quality_metrics, em_scaled_quality_metrics = draw_and_measure(\n",
    "    #         pivots=params[\"empirical\"][\"pivots\"],\n",
    "    #         iterations=params[\"empirical\"][\"iterations\"],\n",
    "    #         eps=params[\"empirical\"][\"eps\"],\n",
    "    #         eg_graph=eg_graph,\n",
    "    #         eg_indices=eg_indices,\n",
    "    #         eg_drawing=eg_drawing,\n",
    "    #         edge_weight=EDGE_WEIGHT,\n",
    "    #         seed=d_seed,\n",
    "    #         n_nodes=len(nx_graph.nodes),\n",
    "    #         n_edges=len(nx_graph.edges),\n",
    "    #         scalers=scalers,\n",
    "    #     )\n",
    "\n",
    "    #     eg_drawing = Drawing.initial_placement(eg_graph)\n",
    "    #     pos, quality_metrics, mu_scaled_quality_metrics = draw_and_measure(\n",
    "    #         pivots=params[\"multi\"][\"pivots\"],\n",
    "    #         iterations=params[\"multi\"][\"iterations\"],\n",
    "    #         eps=params[\"multi\"][\"eps\"],\n",
    "    #         eg_graph=eg_graph,\n",
    "    #         eg_indices=eg_indices,\n",
    "    #         eg_drawing=eg_drawing,\n",
    "    #         edge_weight=EDGE_WEIGHT,\n",
    "    #         seed=d_seed,\n",
    "    #         n_nodes=len(nx_graph.nodes),\n",
    "    #         n_edges=len(nx_graph.edges),\n",
    "    #         scalers=scalers,\n",
    "    #     )\n",
    "\n",
    "    #     eg_drawing = Drawing.initial_placement(eg_graph)\n",
    "    #     pos, quality_metrics, si_scaled_quality_metrics = draw_and_measure(\n",
    "    #         pivots=params[\"single\"][\"pivots\"],\n",
    "    #         iterations=params[\"single\"][\"iterations\"],\n",
    "    #         eps=params[\"single\"][\"eps\"],\n",
    "    #         eg_graph=eg_graph,\n",
    "    #         eg_indices=eg_indices,\n",
    "    #         eg_drawing=eg_drawing,\n",
    "    #         edge_weight=EDGE_WEIGHT,\n",
    "    #         seed=d_seed,\n",
    "    #         n_nodes=len(nx_graph.nodes),\n",
    "    #         n_edges=len(nx_graph.edges),\n",
    "    #         scalers=scalers,\n",
    "    #     )\n",
    "\n",
    "    #     for qm_name in qm_names:\n",
    "    #         empirical[qm_name] += em_scaled_quality_metrics[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "for d_name in d_names:\n",
    "    shuffle(export_data[d_name])\n",
    "\n",
    "with open(ex_path.joinpath(\"data/ex2/data.json\"), mode=\"w\") as f:\n",
    "    json.dump(export_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
