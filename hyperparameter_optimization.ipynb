{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuga_takata/dev/vdslab-project/hyperparameter_optimization/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import Delaunay\n",
    "import py4cytoscape as p4c\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import optuna\n",
    "from egraph import Graph, Coordinates, Rng, SparseSgd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGE_WEIGHT = 30\n",
    "K_FROM = 1\n",
    "K_TO = 20\n",
    "\n",
    "LARGE_DATASET_NAMES = [\n",
    "    '3elt.json',\n",
    "    '1138_bus.json',\n",
    "    'dwt_1005.json',\n",
    "    'dwt_2680.json',\n",
    "    'poli.json',\n",
    "    'qh882.json',\n",
    "    'USpowerGrid.json',\n",
    "]\n",
    "SMALL_DATASET_NAMES = [\n",
    "    'bull.json',\n",
    "    'chvatal.json',\n",
    "    'cubical.json',\n",
    "    'davis_southern_women.json',\n",
    "    'desargues.json',\n",
    "    'diamond.json',\n",
    "    'dodecahedral.json',\n",
    "    'florentine_families.json',\n",
    "    'frucht.json',\n",
    "    'heawood.json',\n",
    "    'hoffman_singleton.json',\n",
    "    'house_x.json',\n",
    "    'house.json',\n",
    "    'icosahedral.json',\n",
    "    'karate_club.json',\n",
    "    'krackhardt_kite.json',\n",
    "    'les_miserables.json',\n",
    "    'moebius_kantor.json',\n",
    "    'octahedral.json',\n",
    "    'pappus.json',\n",
    "    'petersen.json',\n",
    "    'sedgewick_maze.json',\n",
    "    'tutte.json',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの生成・読み込み\n",
    "\n",
    "def generate_graph_from_nx_graph(nx_graph):\n",
    "    graph = Graph()\n",
    "\n",
    "    indices = {}\n",
    "    for u in nx_graph.nodes:\n",
    "        indices[u] = graph.add_node(u)\n",
    "    for u, v in nx_graph.edges:\n",
    "        graph.add_edge(indices[u], indices[v], (u, v))\n",
    "\n",
    "    return graph, indices\n",
    "\n",
    "\n",
    "def graph_preprocessing(nx_graph):\n",
    "    nx_graph = nx.Graph(nx_graph)\n",
    "\n",
    "    # グラフを無向グラフに\n",
    "    nx_graph = nx_graph.to_undirected()\n",
    "\n",
    "    # エッジの自己ループを除去\n",
    "    nx_graph.remove_edges_from(list(nx.selfloop_edges(nx_graph)))\n",
    "\n",
    "    # 最大連結成分を用いる\n",
    "    largest_cc = max(nx.connected_components(nx_graph), key=len)\n",
    "    largest_cc_graph = nx_graph.subgraph(largest_cc)\n",
    "\n",
    "    new_graph = nx.Graph()\n",
    "    nodes = [str(node_id) for node_id in largest_cc_graph.nodes]\n",
    "    new_graph.add_nodes_from(nodes)\n",
    "\n",
    "    # エッジにidと重みを追加\n",
    "    for i, edge in enumerate(largest_cc_graph.edges):\n",
    "        new_graph.add_edge(str(edge[0]), str(\n",
    "            edge[1]), weight=EDGE_WEIGHT, id=str(i))\n",
    "        # weighted_edges.append((str(edge[0]), str(edge[1]), EDGE_WEIGHT))\n",
    "\n",
    "    return new_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_based_metrics\n",
    "def generate_delaunay_triangulation_graph(pos):\n",
    "    index_id_map = {}\n",
    "    pos_array = []\n",
    "    for index, node_id in enumerate(pos):\n",
    "        positions = pos[node_id]\n",
    "        position = [positions[0], positions[1]]\n",
    "        pos_array.append(position)\n",
    "        index_id_map[index] = node_id\n",
    "\n",
    "    pos_ndarray = np.array(pos_array)\n",
    "    delaunay = Delaunay(pos_ndarray)\n",
    "\n",
    "    delaunay_triangulation_graph = nx.Graph()\n",
    "\n",
    "    nodes = [node_id for node_id in pos]\n",
    "    delaunay_triangulation_graph.add_nodes_from(nodes)\n",
    "\n",
    "    weighted_edges = []\n",
    "    for n in delaunay.simplices:\n",
    "        n0 = n[0]\n",
    "        n1 = n[1]\n",
    "        n2 = n[2]\n",
    "        weighted_edges.append(\n",
    "            (index_id_map[n0], index_id_map[n1], EDGE_WEIGHT))\n",
    "        weighted_edges.append(\n",
    "            (index_id_map[n0], index_id_map[n2], EDGE_WEIGHT))\n",
    "        weighted_edges.append(\n",
    "            (index_id_map[n1], index_id_map[n2], EDGE_WEIGHT))\n",
    "    delaunay_triangulation_graph.add_weighted_edges_from(weighted_edges)\n",
    "\n",
    "    return delaunay_triangulation_graph\n",
    "\n",
    "\n",
    "def jaccard_similarity_sum(nx_graph, nx_shape_graph):\n",
    "    j_s_sum = 0\n",
    "    for node in nx_graph.nodes:\n",
    "        g_n = [n for n in nx_graph.neighbors(node)]\n",
    "        s_n = [n for n in nx_shape_graph.neighbors(node)]\n",
    "        and_n = list(set(g_n) & set(s_n))\n",
    "        or_n = list(set(g_n + s_n))\n",
    "\n",
    "        j_s_sum += len(and_n) / len(or_n)\n",
    "\n",
    "    return j_s_sum / len(nx_graph.nodes)\n",
    "\n",
    "# maximize\n",
    "\n",
    "\n",
    "def shape_based_metrics(nx_graph, pos):\n",
    "    nx_shape_graph = generate_delaunay_triangulation_graph(pos)\n",
    "\n",
    "    return jaccard_similarity_sum(nx_graph, nx_shape_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize\n",
    "def stress(nx_graph, pos, K=1, L=1):\n",
    "    shortest_paths = dict(nx.all_pairs_dijkstra_path_length(nx_graph))\n",
    "    s = 0\n",
    "    node_ids = sorted([node_id for node_id in pos])\n",
    "    for i, sid in enumerate(node_ids):\n",
    "        for tid in node_ids[i + 1:]:\n",
    "            norm = np.linalg.norm(np.array(pos[sid]) - np.array(pos[tid]))\n",
    "            dij = shortest_paths[sid][tid]\n",
    "            lij = L * dij\n",
    "            kij = K * dij\n",
    "            e = (kij * ((norm - lij) ** 2)) / 2\n",
    "\n",
    "            s += e\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize\n",
    "def ideal_edge_length(nx_graph, pos):\n",
    "    s = 0\n",
    "    for source, target, data in nx_graph.edges(data=True):\n",
    "        weight = data['weight'] if 'weight' in data else 1\n",
    "        shortest_path_length = nx.shortest_path_length(\n",
    "            nx_graph, source, target, data['weight'] if 'weight' in data else None)\n",
    "\n",
    "        lij = shortest_path_length * weight\n",
    "        dist = np.linalg.norm(np.array(pos[source]) - np.array(pos[target]))\n",
    "        s += ((dist - lij) / lij) ** 2\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_edge_crossing(p1, p2, p3, p4):\n",
    "    tc1 = (p1[0] - p2[0]) * (p3[1] - p1[1]) + (p1[1] - p2[1]) * (p1[0] - p3[0])\n",
    "    tc2 = (p1[0] - p2[0]) * (p4[1] - p1[1]) + (p1[1] - p2[1]) * (p1[0] - p4[0])\n",
    "    td1 = (p3[0] - p4[0]) * (p1[1] - p3[1]) + (p3[1] - p4[1]) * (p3[0] - p1[0])\n",
    "    td2 = (p3[0] - p4[0]) * (p2[1] - p3[1]) + (p3[1] - p4[1]) * (p3[0] - p2[0])\n",
    "    return tc1 * tc2 < 0 and td1 * td2 < 0\n",
    "\n",
    "\n",
    "def edge_crossing_finder(nx_graph, pos):\n",
    "    edges = {}\n",
    "    for s1, t1, attr1 in nx_graph.edges(data=True):\n",
    "        id1 = attr1['id']\n",
    "        if id1 not in edges:\n",
    "            edges[id1] = {}\n",
    "        for s2, t2, attr2 in nx_graph.edges(data=True):\n",
    "            id2 = attr2['id']\n",
    "            crossing = is_edge_crossing(pos[s1], pos[t1], pos[s2], pos[t2])\n",
    "            edges[id1][id2] = crossing\n",
    "\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize\n",
    "def crossing_number(nx_graph, pos, edge_crossing=None):\n",
    "    if edge_crossing is None:\n",
    "        edge_crossing = edge_crossing_finder(nx_graph, pos)\n",
    "\n",
    "    s = 0\n",
    "    node_ids = sorted([node_id for node_id in edge_crossing])\n",
    "    for i, sid in enumerate(node_ids):\n",
    "        for tid in node_ids[i + 1:]:\n",
    "            if edge_crossing[sid][tid]:\n",
    "                s += 1\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximize\n",
    "def crossing_angle_maximization(nx_graph, pos, edge_crossing=None):\n",
    "    if edge_crossing is None:\n",
    "        edge_crossing = edge_crossing_finder(nx_graph, pos)\n",
    "    s = 0\n",
    "    for s1, t1, attr1 in nx_graph.edges(data=True):\n",
    "        id1 = attr1['id']\n",
    "        for s2, t2, attr2 in nx_graph.edges(data=True):\n",
    "            id2 = attr2['id']\n",
    "            if edge_crossing[id1][id2] or edge_crossing[id2][id1]:\n",
    "                e1 = np.array(pos[s1]) - np.array(pos[t1])\n",
    "                e2 = np.array(pos[s2]) - np.array(pos[t2])\n",
    "                s += np.dot(e1, e2) / (np.linalg.norm(e1) * np.linalg.norm(e2))\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravity_center(pos):\n",
    "    gx = 0\n",
    "    gy = 0\n",
    "    for node_id in pos:\n",
    "        x, y = pos[node_id]\n",
    "        gx += x\n",
    "        gy += y\n",
    "\n",
    "    gx /= len(pos)\n",
    "    gy /= len(pos)\n",
    "\n",
    "    return gx, gy\n",
    "\n",
    "# maximize\n",
    "\n",
    "\n",
    "def aspect_ratio(pos):\n",
    "    gravity_centered_pos = []\n",
    "    gx, gy = gravity_center(pos)\n",
    "    for node_id in pos:\n",
    "        x, y = pos[node_id]\n",
    "        gravity_centered_pos.append([x - gx, y - gy])\n",
    "    gravity_centered_pos = np.array(gravity_centered_pos)\n",
    "    _, s, _ = np.linalg.svd(gravity_centered_pos, full_matrices=True)\n",
    "    a = max(s)\n",
    "    b = min(s)\n",
    "\n",
    "    return b / a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_degree(nx_graph):\n",
    "    md = 0\n",
    "    for node_id in nx_graph.nodes:\n",
    "        d = nx_graph.degree[node_id]\n",
    "        if md < d:\n",
    "            md = d\n",
    "\n",
    "    return md\n",
    "\n",
    "# maximize\n",
    "# すべてのノードについて、あるノードに入射するエッジ同士のなす角度が最も小さいもの\n",
    "\n",
    "\n",
    "def angular_resolution(nx_graph, pos):\n",
    "    edges = {}\n",
    "    for s, t in nx_graph.edges:\n",
    "        if s not in edges:\n",
    "            edges[s] = {}\n",
    "        if t not in edges:\n",
    "            edges[t] = {}\n",
    "        edges[s][t] = True\n",
    "        edges[t][s] = True\n",
    "\n",
    "    ls = 0\n",
    "    for s in pos:\n",
    "        if s not in edges:\n",
    "            continue\n",
    "        l = 2 * math.pi\n",
    "        ts = sorted([node_id for node_id in edges[s]])\n",
    "        for i, t1 in enumerate(ts):\n",
    "            e1 = np.array(pos[s]) - np.array(pos[t1])\n",
    "            for t2 in ts[i + 1:]:\n",
    "                if t1 == t2 or s == t1 or s == t2:\n",
    "                    continue\n",
    "                e2 = np.array(pos[s]) - np.array(pos[t2])\n",
    "                angle = math.acos(\n",
    "                    np.dot(e1, e2) / (np.linalg.norm(e1) * np.linalg.norm(e2)))\n",
    "                if angle < l:\n",
    "                    l = angle\n",
    "        ls += l\n",
    "    return ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximize\n",
    "# ノードのユークリッド距離として定義される。stressなどと一致させるために正規化するらしいけど多分必要ない\n",
    "def node_resolution(pos):\n",
    "    nodes = sorted([node_id for node_id in pos])\n",
    "    r = float('inf')\n",
    "    ds = []\n",
    "    for i, sid in enumerate(nodes):\n",
    "        for tid in nodes[i + 1:]:\n",
    "            dist = np.linalg.norm(np.array(pos[sid]) - np.array(pos[tid]))\n",
    "            ds.append(dist)\n",
    "            if dist < r:\n",
    "                r = dist\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimize\n",
    "# エッジを直径とした円の内部にノードを含まないようにしたい。\n",
    "# そこで内部に含まれる点\n",
    "def gabriel_graph_property(nx_graph, pos):\n",
    "    s = 0\n",
    "    for e in nx_graph.edges:\n",
    "        e1, e2 = e\n",
    "        x1 = np.array(pos[e1])\n",
    "        x2 = np.array(pos[e2])\n",
    "        rij = np.linalg.norm(x1 - x2) / 2\n",
    "        cij = (np.array(x1) + np.array(x2)) / 2\n",
    "        for node_id in nx_graph.nodes:\n",
    "            if e1 == node_id or e2 == node_id:\n",
    "                continue\n",
    "            s += max(0, rij - np.linalg.norm(np.array(pos[node_id] - cij)))\n",
    "\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフの描画\n",
    "\n",
    "def draw_graph(graph, indices, params):\n",
    "    drawing = Coordinates.initial_placement(graph)\n",
    "    rng = Rng.seed_from(0)  # random seed\n",
    "    sgd = SparseSgd(\n",
    "        graph,\n",
    "        lambda _: params['edge_length'],  # edge length\n",
    "        params['number_of_pivots'],  # number of pivots\n",
    "        rng,\n",
    "    )\n",
    "    scheduler = sgd.scheduler(\n",
    "        params['number_of_iterations'],  # number of iterations\n",
    "        params['eps'],  # eps: eta_min = eps * min d[i, j] ^ 2\n",
    "    )\n",
    "\n",
    "    def step(eta):\n",
    "        sgd.shuffle(rng)\n",
    "        sgd.apply(drawing, eta)\n",
    "\n",
    "    scheduler.run(step)\n",
    "\n",
    "    pos = {u: (drawing.x(i), drawing.y(i)) for u, i in indices.items()}\n",
    "\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_quality_metrics(nx_graph, pos):\n",
    "    edge_crossing = edge_crossing_finder(nx_graph, pos)\n",
    "\n",
    "    quality_metrics = {}\n",
    "    quality_metrics['stress'] = stress(nx_graph, pos)\n",
    "    quality_metrics['ideal_edge_length'] = ideal_edge_length(nx_graph, pos)\n",
    "    quality_metrics['shape_based_metrics'] = shape_based_metrics(nx_graph, pos)\n",
    "    quality_metrics['crossing_number'] = crossing_number(\n",
    "        nx_graph, pos, edge_crossing)\n",
    "    quality_metrics['crossing_angle_maximization'] = crossing_angle_maximization(\n",
    "        nx_graph, pos, edge_crossing)\n",
    "    quality_metrics['aspect_ratio'] = aspect_ratio(pos)\n",
    "    quality_metrics['angular_resolution'] = angular_resolution(nx_graph, pos)\n",
    "    quality_metrics['node_resolution'] = node_resolution(pos)\n",
    "    quality_metrics['gabriel_graph_property'] = gabriel_graph_property(\n",
    "        nx_graph, pos)\n",
    "\n",
    "    return quality_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = None\n",
    "DATASET_NAME = 'USpowerGrid.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pos = []\n",
    "\n",
    "\n",
    "def objective_wrapper(nx_graph, graph, indices, quality_metrics_names):\n",
    "    def objective(trial: optuna.Trial):\n",
    "        params = {\n",
    "            'edge_length': trial.suggest_int('edge_length', 1, 100),\n",
    "            'number_of_pivots': trial.suggest_int('number_of_pivots', 1, len(nx_graph.nodes)),\n",
    "            'number_of_iterations': trial.suggest_int('number_of_iterations', 1, 1000),\n",
    "            'eps': trial.suggest_float('eps', 0.01, 1)\n",
    "        }\n",
    "\n",
    "        pos = draw_graph(graph, indices, params)\n",
    "        trial.set_user_attr('pos', pos)\n",
    "        global_pos.append(pos)\n",
    "\n",
    "        quality_metrics = calc_quality_metrics(nx_graph, pos)\n",
    "        return tuple([quality_metrics[name] for name in quality_metrics_names])\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAYOUT_NAME = 'kamada-kawai'\n",
    "\n",
    "\n",
    "# def objective_wrapper(nx_graph, graph, indices, quality_metrics_names):\n",
    "#     def objective(trial: optuna.Trial):\n",
    "#         p4c.delete_all_networks()\n",
    "#         p4c.create_network_from_networkx(nx_graph)\n",
    "\n",
    "#         params = {\n",
    "#             'm_averageIterationsPerNode': trial.suggest_float('m_averageIterationsPerNode', 0, 100),\n",
    "#             'm_nodeDistanceStrengthConstant': trial.suggest_float('m_nodeDistanceStrengthConstant', 0, 50),\n",
    "#             'm_nodeDistanceRestLengthConstant': trial.suggest_float('m_nodeDistanceRestLengthConstant', 0, 100),\n",
    "#             'm_disconnectedNodeDistanceSpringStrength': trial.suggest_float('m_disconnectedNodeDistanceSpringStrength', 0, 1),\n",
    "#             'm_disconnectedNodeDistanceSpringRestLength': trial.suggest_float('m_disconnectedNodeDistanceSpringRestLength', 0, 10000),\n",
    "#             'm_anticollisionSpringStrength': trial.suggest_float('m_anticollisionSpringStrength', 0, 1),\n",
    "#             'm_layoutPass': trial.suggest_int('m_layoutPass', 0, 5),\n",
    "#             'singlePartition': False,\n",
    "#             'unweighted': False,\n",
    "#             'randomize': False\n",
    "#         }\n",
    "\n",
    "#         p4c.set_layout_properties(\n",
    "#             layout_name=LAYOUT_NAME, properties_dict=params)\n",
    "#         p4c.layout_network(layout_name=LAYOUT_NAME)\n",
    "#         pos = p4c.get_node_position()\n",
    "\n",
    "#         pos = draw_graph(graph, indices, params)\n",
    "\n",
    "#         quality_metrics = calc_quality_metrics(nx_graph, pos)\n",
    "#         return tuple([quality_metrics[name] for name in quality_metrics_names])\n",
    "#     return objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'lib/egraph-rs/js/dataset/'\n",
    "with open(dir + DATASET_NAME) as f:\n",
    "    graph_data = json.load(f)\n",
    "nx_graph = graph_preprocessing(nx.node_link_graph(graph_data))\n",
    "graph, indices = generate_graph_from_nx_graph(nx_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTION = {'max': 'maximize', 'min': \"minimize\"}\n",
    "\n",
    "quality_metrics_direction = {}\n",
    "quality_metrics_direction['stress'] = DIRECTION['min']\n",
    "quality_metrics_direction['ideal_edge_length'] = DIRECTION['min']\n",
    "quality_metrics_direction['shape_based_metrics'] = DIRECTION['max']\n",
    "quality_metrics_direction['crossing_number'] = DIRECTION['min']\n",
    "quality_metrics_direction['crossing_angle_maximization'] = DIRECTION['max']\n",
    "quality_metrics_direction['aspect_ratio'] = DIRECTION['max']\n",
    "quality_metrics_direction['angular_resolution'] = DIRECTION['max']\n",
    "quality_metrics_direction['node_resolution'] = DIRECTION['max']\n",
    "quality_metrics_direction['gabriel_graph_property'] = DIRECTION['min']\n",
    "\n",
    "quality_metrics_names = sorted([k for k in quality_metrics_direction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_TRIALS = 20\n",
    "# study = optuna.create_study(\n",
    "#     directions=[quality_metrics_direction[name] for name in quality_metrics_names])\n",
    "\n",
    "# study.optimize(objective_wrapper(nx_graph, graph, indices,\n",
    "#                quality_metrics_names), n_trials=N_TRIALS, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "\n",
    "# for best_trial in study.best_trials:\n",
    "#     params = best_trial.params\n",
    "\n",
    "#     data.append(params)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_params.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# data['results'] = []\n",
    "# data['quality_metrics_names'] = quality_metrics_names\n",
    "# for best_trial in study.best_trials:\n",
    "#     values = best_trial.values\n",
    "#     data['results'].append(values)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_results.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# data = {}\n",
    "# data['quality_metrics_names'] = quality_metrics_names\n",
    "# data['result'] = []\n",
    "# data['params'] = []\n",
    "# data['pos'] = []\n",
    "\n",
    "# trials = 5\n",
    "\n",
    "# for _ in range(trials):\n",
    "#     params = {\n",
    "#         'edge_length': random.randint(1, 100),\n",
    "#         'number_of_pivots': random.randint(1, len(nx_graph.nodes)),\n",
    "#         'number_of_iterations': random.randint(1, 1000),\n",
    "#         'eps': random.uniform(0.01, 1)\n",
    "#     }\n",
    "\n",
    "#     pos = draw_graph(graph, indices, params)\n",
    "\n",
    "#     quality_metrics = calc_quality_metrics(nx_graph, pos)\n",
    "#     values = [quality_metrics[name] for name in quality_metrics_names]\n",
    "\n",
    "#     data['result'].append(values)\n",
    "#     data['params'].append(params)\n",
    "#     data['pos'].append(pos)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_randomized_data.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'edge_length': 60, 'number_of_pivots': 1322, 'number_of_iterations': 681, 'eps': 0.8502822373438783}\n",
      "{'edge_length': 26, 'number_of_pivots': 281, 'number_of_iterations': 867, 'eps': 0.4001671578513263}\n",
      "{'edge_length': 69, 'number_of_pivots': 1898, 'number_of_iterations': 517, 'eps': 0.33002499120244505}\n",
      "{'edge_length': 30, 'number_of_pivots': 1502, 'number_of_iterations': 482, 'eps': 0.4768008887987786}\n",
      "{'edge_length': 69, 'number_of_pivots': 2915, 'number_of_iterations': 181, 'eps': 0.03620086344394183}\n",
      "{'edge_length': 92, 'number_of_pivots': 2699, 'number_of_iterations': 266, 'eps': 0.023059806189874736}\n",
      "{'edge_length': 85, 'number_of_pivots': 2523, 'number_of_iterations': 908, 'eps': 0.9593103420065461}\n",
      "{'edge_length': 58, 'number_of_pivots': 4016, 'number_of_iterations': 568, 'eps': 0.046034308378419764}\n",
      "{'edge_length': 47, 'number_of_pivots': 1980, 'number_of_iterations': 451, 'eps': 0.21243852974511238}\n",
      "{'edge_length': 43, 'number_of_pivots': 260, 'number_of_iterations': 468, 'eps': 0.9548669985140409}\n",
      "{'edge_length': 43, 'number_of_pivots': 1616, 'number_of_iterations': 645, 'eps': 0.508579718630267}\n",
      "{'edge_length': 87, 'number_of_pivots': 2492, 'number_of_iterations': 485, 'eps': 0.3482740291590319}\n",
      "{'edge_length': 25, 'number_of_pivots': 205, 'number_of_iterations': 147, 'eps': 0.8219975609141387}\n",
      "{'edge_length': 81, 'number_of_pivots': 3474, 'number_of_iterations': 90, 'eps': 0.9972204736292728}\n",
      "{'edge_length': 24, 'number_of_pivots': 3753, 'number_of_iterations': 647, 'eps': 0.17950424620772534}\n",
      "{'edge_length': 36, 'number_of_pivots': 3596, 'number_of_iterations': 207, 'eps': 0.6770280812844968}\n",
      "{'edge_length': 52, 'number_of_pivots': 2382, 'number_of_iterations': 629, 'eps': 0.10611970570708336}\n",
      "{'edge_length': 49, 'number_of_pivots': 622, 'number_of_iterations': 403, 'eps': 0.988841884043843}\n",
      "{'edge_length': 14, 'number_of_pivots': 2427, 'number_of_iterations': 260, 'eps': 0.15672077134076282}\n"
     ]
    }
   ],
   "source": [
    "with open(f'data/{DATASET_NAME.split(\".\")[0]}_optimized_data_nopos.json') as f:\n",
    "    jsondata = json.load(f)\n",
    "\n",
    "dir = 'lib/egraph-rs/js/dataset/'\n",
    "with open(dir + DATASET_NAME) as f:\n",
    "    graph_data = json.load(f)\n",
    "nx_graph = graph_preprocessing(nx.node_link_graph(graph_data))\n",
    "graph, indices = generate_graph_from_nx_graph(nx_graph)\n",
    "\n",
    "\n",
    "jsondata['pos'] = []\n",
    "for p in jsondata['params']:\n",
    "    pos = draw_graph(graph, indices, p)\n",
    "    jsondata['pos'].append(pos)\n",
    "    print(p)\n",
    "\n",
    "\n",
    "filename = f'{DATASET_NAME.split(\".\")[0]}_optimized_data.json'\n",
    "with open(f'data/{filename}', mode='w') as f:\n",
    "    json.dump(jsondata, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = []\n",
    "\n",
    "# for best_trial in study.best_trials:\n",
    "#     params = best_trial.params\n",
    "\n",
    "#     data.append(params)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_random_params.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# data['results'] = []\n",
    "# data['quality_metrics_names'] = quality_metrics_names\n",
    "# for best_trial in study.best_trials:\n",
    "#     values = best_trial.values\n",
    "#     data['results'].append(values)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_random_results.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {}\n",
    "# data['results'] = []\n",
    "# data['quality_metrics_names'] = quality_metrics_names\n",
    "# for best_trial in study.best_trials:\n",
    "#     values = best_trial.values\n",
    "#     data['results'].append(values)\n",
    "\n",
    "# filename = f'{DATASET_NAME.split(\".\")[0]}_random_pos.json'\n",
    "# with open(f'data/{filename}', mode='w') as f:\n",
    "#     json.dump(data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5031a1c082d374b42824ba4074361c835f9bfd3c33854874e61fd39ef2ddb484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
