{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 各パラメータごとに非線形回帰を行う\n",
    "- このとき、対象パラメータが20通り存在するので、それぞれについて回帰線を出す\n",
    "  - 対象ではないパラメータについては、全ての組み合わせ（対象パラメータを持つ全データ）を利用する\n",
    "- 複数のグラフの上記回帰線を重ねてみる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\"les_miserables\", \"1138_bus\", \"USpowerGrid\"]\n",
    "PARAMS_NAMES = [\"number_of_pivots\", \"number_of_iterations\", \"eps\"]\n",
    "COLOR_MAP = {\n",
    "    DATASET_NAMES[0]: 'red',\n",
    "    DATASET_NAMES[1]: \"green\",\n",
    "    DATASET_NAMES[2]: 'blue'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party Library\n",
    "import pandas as pd\n",
    "\n",
    "# First Party Library\n",
    "from config.paths import get_project_root_path\n",
    "\n",
    "\n",
    "def generate_data_df_dict(dataset_names):\n",
    "    EXPERIENT_DATA_DIR = (\n",
    "        get_project_root_path()\n",
    "        .joinpath(\"data\")\n",
    "        .joinpath(\"experiments\")\n",
    "        .joinpath(\"regression_analysis\")\n",
    "    )\n",
    "\n",
    "    data_df_dict = {}\n",
    "    for dataset_name in dataset_names:\n",
    "        data_path = EXPERIENT_DATA_DIR.joinpath(\"grid\").joinpath(\n",
    "            f\"{dataset_name}-without-pos.pkl\"\n",
    "        )\n",
    "        data_df_dict[dataset_name] = pd.read_pickle(data_path)\n",
    "\n",
    "    return data_df_dict\n",
    "\n",
    "\n",
    "def generate_params_candidates():\n",
    "    params_steps = {\n",
    "        \"number_of_pivots\": 5,\n",
    "        \"number_of_iterations\": 10,\n",
    "        \"eps\": 0.05,\n",
    "    }\n",
    "\n",
    "    params_candidates = {}\n",
    "    params_names = [\"number_of_pivots\", \"number_of_iterations\", \"eps\"]\n",
    "    for params_name in params_names:\n",
    "        params_candidates[params_name] = [\n",
    "            v * params_steps[params_name] for v in list(range(1, 20 + 1))\n",
    "        ]\n",
    "\n",
    "    return params_candidates\n",
    "\n",
    "\n",
    "data_df_dict = generate_data_df_dict(DATASET_NAMES)\n",
    "params_candidates = generate_params_candidates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/db_nbhl55hvds1mt0zx_p14h0000gn/T/ipykernel_3714/3256811984.py:92: UserWarning: Legend does not support handles for list instances.\n",
      "A proxy artist may be used instead.\n",
      "See: https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html#controlling-the-legend-entries\n",
      "  axis.legend([legends[key] for key in legends], DATASET_NAMES)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "from config.paths import get_project_root_path\n",
    "from config.quality_metrics import ALL_QM_NAMES\n",
    "\n",
    "# sscaler = MinMaxScaler()\n",
    "sscaler = StandardScaler()\n",
    "\n",
    "deg = 5\n",
    "\n",
    "# sscaler_map = {}\n",
    "# for params_name in PARAMS_NAMES:\n",
    "#     # params_name以外のパラメータの組み合わせ作成\n",
    "#     params_t = list(filter(lambda x: x != params_name, PARAMS_NAMES))\n",
    "#     comb = list(\n",
    "#         product(params_candidates[params_t[0]], params_candidates[params_t[1]])\n",
    "#     )\n",
    "#     for qm_name in ALL_QM_NAMES:\n",
    "#         fig, axis = plt.subplots(1, 1, figsize=(8, 8))\n",
    "#         fig.subplots_adjust(left=0.04, right=0.98, bottom=0.05, top=0.95)\n",
    "#         legends = {}\n",
    "#         for dataset_name in DATASET_NAMES:\n",
    "\n",
    "data_y_dict = {}\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    data_y_dict[dataset_name] = {}\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        data_y_dict[dataset_name][qm_name] = np.array(data_df_dict[dataset_name][qm_name]).reshape(-1, 1)\n",
    "\n",
    "for params_name in PARAMS_NAMES:\n",
    "    # params_name以外のパラメータの組み合わせ作成\n",
    "    params_t = list(filter(lambda x: x != params_name, PARAMS_NAMES))\n",
    "    comb = list(\n",
    "        product(params_candidates[params_t[0]], params_candidates[params_t[1]])\n",
    "    )\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        fig, axis = plt.subplots(1, 1, figsize=(8, 8))\n",
    "        fig.subplots_adjust(left=0.04, right=0.98, bottom=0.05, top=0.95)\n",
    "        legends = {}\n",
    "        for dataset_name in DATASET_NAMES:\n",
    "            for c in comb:\n",
    "                df = data_df_dict[dataset_name]\n",
    "                df = df.query(\n",
    "                    \" & \".join(\n",
    "                        [\n",
    "                            f\"{item[1]} == {item[0]}\"\n",
    "                            for item in zip(c, params_t)\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                x = df[params_name]\n",
    "                y = df[qm_name]\n",
    "                x = np.array(x).reshape(-1, 1)\n",
    "                y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "                sscaler.fit(data_y_dict[dataset_name][qm_name])\n",
    "                yss = sscaler.transform(y)\n",
    "\n",
    "                regr = Pipeline(\n",
    "                    [\n",
    "                        (\"poly\", PolynomialFeatures(degree=deg)),\n",
    "                        (\"linear\", LinearRegression()),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                regr.fit(x, yss)\n",
    "\n",
    "                ux = np.unique(x).reshape(-1, 1)\n",
    "                p_poly = regr.predict(ux)\n",
    "\n",
    "                axis.scatter(\n",
    "                    x, yss, color=COLOR_MAP[dataset_name], alpha=0.1\n",
    "                )\n",
    "                line = axis.plot(\n",
    "                    ux,\n",
    "                    p_poly,\n",
    "                    color=COLOR_MAP[dataset_name],\n",
    "                    alpha=0.1,\n",
    "                    label=dataset_name,\n",
    "                )\n",
    "                if dataset_name not in legends:\n",
    "                    legends[dataset_name] = line\n",
    "                axis.set_title(f\"{qm_name}\")\n",
    "                # axis.set_title(\n",
    "                #     f'{qm_name}-{\"R^2={:.3f}\".format(regr.score(x, y))}'\n",
    "                # )\n",
    "        axis.legend([legends[key] for key in legends], DATASET_NAMES)\n",
    "        \n",
    "        # export_path = (\n",
    "        #     get_project_root_path()\n",
    "        #     .joinpath(\"data\")\n",
    "        #     .joinpath(\"experiments\")\n",
    "        #     .joinpath(\"regression_analysis\")\n",
    "        #     .joinpath(\"params\")\n",
    "        #     .joinpath(\"overlap\")\n",
    "        #     .joinpath(f\"{params_name}-{qm_name}.png\")\n",
    "        # )\n",
    "        # export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # plt.savefig(export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "\n",
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new(\"RGB\", (im1.width + im2.width, im1.height), \"black\")\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    dst = Image.new(\"RGB\", (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "image_path = (\n",
    "    get_project_root_path()\n",
    "    .joinpath(\"data\")\n",
    "    .joinpath(\"experiments\")\n",
    "    .joinpath(\"regression_analysis\")\n",
    "    .joinpath(\"params\")\n",
    "    .joinpath('overlap')\n",
    ")\n",
    "image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "for params_name in PARAMS_NAMES:\n",
    "    images = []\n",
    "    tmp = []\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        img_path = image_path.joinpath(f\"{params_name}-{qm_name}.png\")\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        tmp.append({\"image\": img})\n",
    "\n",
    "        if len(tmp) == 3:\n",
    "            images.append(tmp)\n",
    "            tmp = []\n",
    "\n",
    "    dst = None\n",
    "    for v in images:\n",
    "        h_dst = None\n",
    "        for h in v:\n",
    "            if h_dst is None:\n",
    "                h_dst = h[\"image\"]\n",
    "                continue\n",
    "            h_dst = get_concat_h(h_dst, h[\"image\"])\n",
    "        if dst is None:\n",
    "            dst = h_dst\n",
    "            continue\n",
    "        dst = get_concat_v(dst, h_dst)\n",
    "    draw = ImageDraw.Draw(dst)\n",
    "    font = ImageFont.truetype(\"Arial.ttf\", 36)\n",
    "    draw.text((40, 40), f\"{params_name}\", \"red\", font=font)\n",
    "    for i, dataset_name in enumerate(DATASET_NAMES):\n",
    "        draw.text((600, 40 * (i + 1)), f'{dataset_name}', COLOR_MAP[dataset_name], font=font)\n",
    "    dst.save(image_path.joinpath(f\"{params_name}.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    for params_name in PARAMS_NAMES:\n",
    "        for qm_name in ALL_QM_NAMES:\n",
    "            img_path = image_path.joinpath(f\"{params_name}-{qm_name}.png\")\n",
    "            os.remove(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
