{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交差検証\n",
    "- どの方法でモデル作るのがいいか調べる\n",
    "  - 多項式（1 - 10次）\n",
    "  - ガウス型基底関数\n",
    "  - 平滑化スプラインモデル\n",
    "  - GAM（general aditive modeel, 一般下方モデル）\n",
    "  - リッジ回帰\n",
    "\n",
    "- 固定Pと全ての非固定Pの値の組み合わせについて回帰モデルを作る\n",
    "  - そのそれぞれのモデルについてk分割交差検証\n",
    "  - 平均を取る\n",
    "- それぞれの回帰モデルごとの平均全体の平均を元に優秀なモデル生成方法を見つける\n",
    "  - とりあえずスコア高ければいいよな？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\"les_miserables\", \"1138_bus\", \"USpowerGrid\"]\n",
    "PARAMS_NAMES = sorted([\"number_of_pivots\", \"number_of_iterations\", \"eps\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party Library\n",
    "import pandas as pd\n",
    "\n",
    "# First Party Library\n",
    "from config.paths import get_project_root_path\n",
    "\n",
    "\n",
    "def generate_data_df_dict(dataset_names):\n",
    "    EXPERIENT_DATA_DIR = (\n",
    "        get_project_root_path()\n",
    "        .joinpath(\"data\")\n",
    "        .joinpath(\"experiments\")\n",
    "        .joinpath(\"regression_analysis\")\n",
    "    )\n",
    "\n",
    "    data_df_dict = {}\n",
    "    for dataset_name in dataset_names:\n",
    "        data_path = EXPERIENT_DATA_DIR.joinpath(\"grid\").joinpath(\n",
    "            f\"{dataset_name}-without-pos.pkl\"\n",
    "        )\n",
    "        data_df_dict[dataset_name] = pd.read_pickle(data_path)\n",
    "\n",
    "    return data_df_dict\n",
    "\n",
    "\n",
    "def generate_params_candidates():\n",
    "    params_steps = {\n",
    "        \"number_of_pivots\": 5,\n",
    "        \"number_of_iterations\": 10,\n",
    "        \"eps\": 0.05,\n",
    "    }\n",
    "\n",
    "    params_candidates = {}\n",
    "    params_name1s = [\"number_of_pivots\", \"number_of_iterations\", \"eps\"]\n",
    "    for params_name1 in params_name1s:\n",
    "        params_candidates[params_name1] = [\n",
    "            v * params_steps[params_name1] for v in list(range(1, 20 + 1))\n",
    "        ]\n",
    "\n",
    "    return params_candidates\n",
    "\n",
    "\n",
    "data_df_dict = generate_data_df_dict(DATASET_NAMES)\n",
    "params_candidates = generate_params_candidates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = [\n",
    "    \"n=1\",\n",
    "    \"n=2\",\n",
    "    \"n=3\",\n",
    "    \"n=4\",\n",
    "    \"n=5\",\n",
    "    \"n=6\",\n",
    "    \"n=7\",\n",
    "    \"n=8\",\n",
    "    \"n=9\",\n",
    "    \"n=10\",\n",
    "    \"gaussian\",\n",
    "    \"spline\",\n",
    "    \"ridge\",\n",
    "]\n",
    "\n",
    "result = {}\n",
    "for model_id in model_ids:\n",
    "    result[model_id] = {}\n",
    "    for dataset_name in DATASET_NAMES:\n",
    "        result[model_id][dataset_name] = {'scores': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_NAMES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m data_y_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m dataset_name \u001b[39min\u001b[39;00m DATASET_NAMES:\n\u001b[1;32m     11\u001b[0m     data_y_dict[dataset_name] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     12\u001b[0m     \u001b[39mfor\u001b[39;00m qm_name \u001b[39min\u001b[39;00m ALL_QM_NAMES:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATASET_NAMES' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import combinations, product\n",
    "import pickle\n",
    "from config.paths import get_project_root_path\n",
    "from config.quality_metrics import ALL_QM_NAMES\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data_y_dict = {}\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    data_y_dict[dataset_name] = {}\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        data_y_dict[dataset_name][qm_name] = np.array(\n",
    "            data_df_dict[dataset_name][qm_name]\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "sscaler = StandardScaler()\n",
    "degs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for params_name in PARAMS_NAMES:\n",
    "    # params_name以外のパラメータの組み合わせ作成\n",
    "    params_t = list(filter(lambda x: x != params_name, PARAMS_NAMES))\n",
    "    comb = list(\n",
    "        product(params_candidates[params_t[0]], params_candidates[params_t[1]])\n",
    "    )\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        for dataset_name in DATASET_NAMES:\n",
    "            for c in comb:\n",
    "                df = data_df_dict[dataset_name]\n",
    "                df = df.query(\n",
    "                    \" & \".join(\n",
    "                        [\n",
    "                            f\"{item[1]} == {item[0]}\"\n",
    "                            for item in zip(c, params_t)\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                x = df[params_name]\n",
    "                y = df[qm_name]\n",
    "                x = np.array(x).reshape(-1, 1)\n",
    "                y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "                sscaler.fit(data_y_dict[dataset_name][qm_name])\n",
    "                yss = sscaler.transform(y)\n",
    "\n",
    "                for deg in degs:\n",
    "                    regr = Pipeline(\n",
    "                        [\n",
    "                            (\"poly\", PolynomialFeatures(degree=deg)),\n",
    "                            (\"linear\", LinearRegression()),\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    rand_state = 0\n",
    "                    kf = KFold()\n",
    "\n",
    "                    regr.fit(x, yss)\n",
    "\n",
    "                    ux = np.unique(x).reshape(-1, 1)\n",
    "                    p_poly = regr.predict(ux)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
