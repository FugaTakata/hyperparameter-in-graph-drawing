{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1138_bus', 'USpowerGrid', 'les_miserables'] ['eps', 'number_of_iterations', 'number_of_pivots']\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAMES = sorted([\"les_miserables\", \"1138_bus\", \"USpowerGrid\"])\n",
    "PARAMS_NAMES = sorted([\"number_of_pivots\", \"number_of_iterations\", \"eps\"])\n",
    "COLOR_MAP = {\n",
    "    DATASET_NAMES[0]: \"red\",\n",
    "    DATASET_NAMES[1]: \"green\",\n",
    "    DATASET_NAMES[2]: \"blue\",\n",
    "}\n",
    "print(DATASET_NAMES, PARAMS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Party Library\n",
    "import pandas as pd\n",
    "\n",
    "# First Party Library\n",
    "from config.paths import get_project_root_path\n",
    "\n",
    "\n",
    "def generate_data_df_dict(dataset_names):\n",
    "    EXPERIENT_DATA_DIR = (\n",
    "        get_project_root_path()\n",
    "        .joinpath(\"data\")\n",
    "        .joinpath(\"experiments\")\n",
    "        .joinpath(\"regression_analysis\")\n",
    "    )\n",
    "\n",
    "    data_df_dict = {}\n",
    "    for dataset_name in dataset_names:\n",
    "        data_path = EXPERIENT_DATA_DIR.joinpath(\"grid\").joinpath(\n",
    "            f\"{dataset_name}-without-pos.pkl\"\n",
    "        )\n",
    "        data_df_dict[dataset_name] = pd.read_pickle(data_path)\n",
    "\n",
    "    return data_df_dict\n",
    "\n",
    "\n",
    "def generate_params_candidates():\n",
    "    params_steps = {\n",
    "        \"number_of_pivots\": 5,\n",
    "        \"number_of_iterations\": 10,\n",
    "        \"eps\": 0.05,\n",
    "    }\n",
    "\n",
    "    params_candidates = {}\n",
    "    params_names = [\"number_of_pivots\", \"number_of_iterations\", \"eps\"]\n",
    "    for params_name in params_names:\n",
    "        params_candidates[params_name] = [\n",
    "            v * params_steps[params_name] for v in list(range(1, 20 + 1))\n",
    "        ]\n",
    "\n",
    "    return params_candidates\n",
    "\n",
    "\n",
    "data_df_dict = generate_data_df_dict(DATASET_NAMES)\n",
    "params_candidates = generate_params_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "from config.paths import get_project_root_path\n",
    "from config.quality_metrics import ALL_QM_NAMES\n",
    "import pickle\n",
    "\n",
    "# sscaler = MinMaxScaler()\n",
    "sscaler = StandardScaler()\n",
    "\n",
    "deg = 5\n",
    "\n",
    "# sscaler_map = {}\n",
    "# for params_name in PARAMS_NAMES:\n",
    "#     # params_name以外のパラメータの組み合わせ作成\n",
    "#     params_t = list(filter(lambda x: x != params_name, PARAMS_NAMES))\n",
    "#     comb = list(\n",
    "#         product(params_candidates[params_t[0]], params_candidates[params_t[1]])\n",
    "#     )\n",
    "#     for qm_name in ALL_QM_NAMES:\n",
    "#         fig, axis = plt.subplots(1, 1, figsize=(8, 8))\n",
    "#         fig.subplots_adjust(left=0.04, right=0.98, bottom=0.05, top=0.95)\n",
    "#         legends = {}\n",
    "#         for dataset_name in DATASET_NAMES:\n",
    "\n",
    "data_y_dict = {}\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    data_y_dict[dataset_name] = {}\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        data_y_dict[dataset_name][qm_name] = np.array(\n",
    "            data_df_dict[dataset_name][qm_name]\n",
    "        ).reshape(-1, 1)\n",
    "\n",
    "for params_name in PARAMS_NAMES:\n",
    "    # params_name以外のパラメータの組み合わせ作成\n",
    "    params_t = list(filter(lambda x: x != params_name, PARAMS_NAMES))\n",
    "    comb = list(\n",
    "        product(params_candidates[params_t[0]], params_candidates[params_t[1]])\n",
    "    )\n",
    "    for qm_name in ALL_QM_NAMES:\n",
    "        for dataset_name in DATASET_NAMES:\n",
    "            for c in comb:\n",
    "                df = data_df_dict[dataset_name]\n",
    "                df = df.query(\n",
    "                    \" & \".join(\n",
    "                        [\n",
    "                            f\"{item[1]} == {item[0]}\"\n",
    "                            for item in zip(c, params_t)\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                x = df[params_name]\n",
    "                y = df[qm_name]\n",
    "                x = np.array(x).reshape(-1, 1)\n",
    "                y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "                sscaler.fit(data_y_dict[dataset_name][qm_name])\n",
    "                yss = sscaler.transform(y)\n",
    "\n",
    "                regr = Pipeline(\n",
    "                    [\n",
    "                        (\"poly\", PolynomialFeatures(degree=deg)),\n",
    "                        (\"linear\", LinearRegression()),\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                regr.fit(x, yss)\n",
    "\n",
    "                # axis.set_title(\n",
    "                #     f'{qm_name}-{\"R^2={:.3f}\".format(regr.score(x, y))}'\n",
    "                # )\n",
    "                params_info = \"-\".join(\n",
    "                    [f\"{item[1]}={item[0]}\" for item in zip(c, params_t)]\n",
    "                )\n",
    "                export_path = (\n",
    "                    get_project_root_path()\n",
    "                    .joinpath(\"data\")\n",
    "                    .joinpath(\"experiments\")\n",
    "                    .joinpath(\"regression_analysis\")\n",
    "                    .joinpath(\"models\")\n",
    "                    .joinpath(\"deg=5-ss\")\n",
    "                    .joinpath(\n",
    "                        f\"{dataset_name}-{qm_name}-{params_name}-{params_info}.pickle\"\n",
    "                    )\n",
    "                )\n",
    "                export_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                with open(export_path, mode=\"wb\") as f:\n",
    "                    pickle.dump(regr, f, protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
